# FocusFind: Fine-Tuned LLM for Focused Online and Offline Search & Summarization

FocusFind is a web application that leverages large language models (LLMs) for both online web search summarization and offline PDF-based question answering. It provides two main modes:
- **Online Mode:** Summarizes web search results and provides evidence from sources.
- **Offline Mode:** Allows uploading a PDF and asking questions based on its content.

---

## Features

- **Web Search Summarization:**  
  Uses Google Custom Search and Gemini LLM to fetch, scrape, and summarize web results, with source evidence.
- **PDF Q&A:**  
  Upload a PDF, ask questions, and get answers based on the document using local embeddings and LLMs.
- **Stock, Weather, and News:**  
  Fetches real-time stock prices, weather, and news headlines.
- **Modern UI:**  
  Responsive, animated, and user-friendly interface.

---

## Folder Structure

```
FocusFind/
│
├── app.py           # Flask app for offline (local PDF) Q&A using Ollama LLM
├── app2.py          # Flask app for PDF upload, embedding, and Q&A
├── dummy2.py        # Flask app for online web search, summarization, and APIs
├── dummy.html       # UI for online search (used by dummy2.py)
├── dummy2.html      # Alternate UI for online search
├── static/
│   └── uploads/
│       └── AdityaC-Resume.pdf   # Example uploaded PDF
├── templates/
│   ├── index.html   # UI for offline PDF Q&A (used by app.py)
│   └── index2.html  # UI for PDF upload/Q&A (used by app2.py)
└── README.md
```

---

## Requirements

- Python 3.8+
- [Flask](https://flask.palletsprojects.com/)
- [sentence-transformers](https://www.sbert.net/)
- [faiss-cpu](https://github.com/facebookresearch/faiss)
- [PyPDF2](https://pypi.org/project/PyPDF2/)
- [Ollama](https://ollama.com/) (for local LLM inference)
- [aiohttp](https://docs.aiohttp.org/)
- [BeautifulSoup4](https://www.crummy.com/software/BeautifulSoup/)
- [Flask-Caching](https://flask-caching.readthedocs.io/)
- [Flask-Limiter](https://flask-limiter.readthedocs.io/)
- [bleach](https://bleach.readthedocs.io/)
- [requests](https://docs.python-requests.org/)
- [python-dotenv](https://pypi.org/project/python-dotenv/)
- Google, Gemini, OpenWeather, AlphaVantage, and NewsAPI keys (for online mode)

Install dependencies:
```sh
pip install flask sentence-transformers faiss-cpu PyPDF2 aiohttp beautifulsoup4 flask-caching flask-limiter bleach requests python-dotenv
```

---

## Usage

### 1. Offline PDF Q&A (Local LLM)
- Start the app:
  ```sh
  python app.py
  ```
- Go to [http://localhost:5000](http://localhost:5000)
- Ask questions (answers generated by local LLM via Ollama).

### 2. PDF Upload & Q&A
- Start the app:
  ```sh
  python app2.py
  ```
- Go to [http://localhost:5000](http://localhost:5000)
- Upload a PDF, then ask questions about its content.

### 3. Online Web Search & Summarization
- Set up a `.env` file with required API keys (see below).
- Start the app:
  ```sh
  python dummy2.py
  ```
- Go to [http://localhost:5001](http://localhost:5001)
- Ask questions; the app will search the web, summarize, and show sources.

---

## Environment Variables

Create a `.env` file in the project root with the following content:
```
GOOGLE_CSE_ID=your_google_cse_id
GOOGLE_API_KEY=your_google_api_key
GEMINI_API_KEY=your_gemini_api_key
OPENWEATHER_API_KEY=your_openweather_api_key
ALPHA_VANTAGE_API_KEY=your_alpha_vantage_api_key
NEWS_API_KEY=your_newsapi_key
```

---

## Notes

- **Ollama** must be installed and running for local LLM inference.
- For online mode, valid API keys are required.
- The UI is available in both `/templates` and as standalone HTML files.

---
